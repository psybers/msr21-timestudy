# Usage

All scripts were tested on OSX Catalina 10.15.7 with zsh 5.7.1 (x86_64-apple-darwin19.0).

## Required software

- make
- python3
- perl5
- curl
- jq (JSON query tool)

### Ubuntu

```sh
apt-get install curl jq
```

### OSX

```sh
brew install curl
brew install jq
```

## Config

1. Create GitHub API token: [https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/creating-a-personal-access-token](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/creating-a-personal-access-token)
2. be sure it has `public_repo` access
3. create the file `github.token` and place the GitHub API token in it

## Boa Queries

All Boa queries were run on the `2019 October/GitHub` dataset.

[Suspiciously 'old' commits](http://boa.cs.iastate.edu/boa/?q=boa/job/public/90164)<br/>
Source: `old-source.boa`<br/>
Output: `old-output.txt`

[Suspiciously 'future' commits](http://boa.cs.iastate.edu/boa/?q=boa/job/public/90973)<br/>
Source: `future-source.boa`<br/>
Output: `future-output.txt`

[Out-of-order commits](http://boa.cs.iastate.edu/boa/?q=boa/job/public/90169)<br/>
Source: `order-source.boa`<br/>
Output: `order-output.txt`

[Count revisions of all projects](http://boa.cs.iastate.edu/boa/?q=boa/job/public/91257)<br/>
Source: `all-projects-revisions.boa`<br/>
Output: `all-projects-revisions-output.txt`

## Scripts

Note that all data generated by these scripts is already included, so you
should not need to re-run any scripts.  But they are here if you wish to
inspect, modify, and/or re-run them yourself.

If you want to just re-run everything, you can run:

```sh
make all
```

Note that this could take a substantial amount of time!

### To generate the list of all GitHub projects found:

```sh
make project-lists
```

### To generate list of good and bad (404) projects:

```sh
make gen-goodbad
```

This generates `good-[sha-]projects.txt` and `bad-[sha-]projects.txt`

The `'bad'` list is used to avoid asking GitHub API for info on deleted
projects.  The `'-sha-'` versions look for the missing GitHub projects on
Software Heritage's archive.

### Cache JSON files

Most of the remaining scripts rely on having JSON metadata for commits.  These
JSON files are already cached in the dataset, but this is how you download tem:

```sh
make cache-json
```

### To generate commit.dates:

```sh
make gen-dates
```

This file is used to inspect the actual commit date of the commit, as reported
by GitHub/SHA.

This also generates the file `bad-commits-by-year.txt`.  This file is used to
generate the filtering by year table for the bad commits.

### To generate the filter by year table:

```sh
make gen-filteryear-table
```

### To generate git-svn.ids:

```sh
make gen-gitsvn
```

### To generate order-verified.txt:

```sh
make gen-verified
```

### To generate logs-**.txt:

```sh
make gen-logs
```

This grabs the other commit logs that are not `git-svn` related and puts into
`logs-old.txt`.

This also generates the commit logs for 'bad' (out of order) commits in
`logs-order.txt`.

### To calculate the number of commits by each user:

```sh
make gen-commit-users
```

### To calculate the number of commits per project:

```sh
make gen-commit-proj
```

### To calculate the number of commits found:

```sh
make gen-commit-loc
```

### To calculate the number of duplicated commits:

```sh
make calc-dupes
```

### To calculate the number of bad commits as percentage:

```sh
make calc-percent-bad
```
